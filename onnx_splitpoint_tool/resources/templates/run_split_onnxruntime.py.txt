#!/usr/bin/env python3
# Auto-generated by onnx_splitpoint_tool
# Runner: ORT benchmark for full / part1 / part2 / composed (+ optional CV viz)
#
# Features:
# - provider selection: CPU / CUDA / TensorRT (with cache + fast-build preset)
# - inputs: random generation, optional --inputs-npz, optional image auto-feed (test_image.png)
# - output diff (max_abs/mean_abs) with --eps
# - optional report plots (validation_report.png/.pdf) if matplotlib is available
# - optional YOLO visualization (detections_*.png/.json) if PIL is available

from __future__ import annotations

import argparse
import json
import os
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import numpy as np
import onnx
import onnxruntime as ort

# Optional deps (runner must still work without them)
try:
    from PIL import Image, ImageDraw  # type: ignore
except Exception:
    Image = None  # type: ignore
    ImageDraw = None  # type: ignore


DEFAULT_MANIFEST = "__MANIFEST_FILENAME__"
DEFAULT_PROVIDER = "__DEFAULT_PROVIDER__"


# ----------------------------
# Small utilities
# ----------------------------
def _read_json(path: Path) -> dict:
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def _write_json(path: Path, obj: dict) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, indent=2, ensure_ascii=False)


def _now_ts() -> str:
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())


def _available_providers() -> List[str]:
    try:
        return list(ort.get_available_providers())
    except Exception:
        return []


def _as_ort_opt(v):
    if isinstance(v, bool):
        return "True" if v else "False"
    return str(v)


def _pick_providers(requested: str, available: List[str]) -> List[str]:
    avail = set(available)
    req = (requested or "auto").lower().strip()

    def keep(lst: List[str]) -> List[str]:
        out = [p for p in lst if p in avail]
        if "CPUExecutionProvider" not in out:
            out.append("CPUExecutionProvider")
        return out

    if req in ("auto", "default"):
        if "TensorrtExecutionProvider" in avail:
            return keep(["TensorrtExecutionProvider", "CUDAExecutionProvider", "CPUExecutionProvider"])
        if "CUDAExecutionProvider" in avail:
            return keep(["CUDAExecutionProvider", "CPUExecutionProvider"])
        return ["CPUExecutionProvider"]

    if req in ("tensorrt", "trt"):
        return keep(["TensorrtExecutionProvider", "CUDAExecutionProvider", "CPUExecutionProvider"])
    if req in ("cuda", "gpu"):
        return keep(["CUDAExecutionProvider", "CPUExecutionProvider"])
    if req in ("cpu",):
        return ["CPUExecutionProvider"]

    raise SystemExit(f"Unknown --provider '{requested}'. Expected: auto|tensorrt|cuda|cpu")


@dataclass
class SessionBuildInfo:
    name: str
    model_path: str
    build_seconds: float
    providers_requested: List[str]
    providers_in_use: List[str]


class _Spinner(threading.Thread):
    def __init__(self, prefix: str, every_sec: float = 1.0):
        super().__init__(daemon=True)
        self.prefix = prefix
        self.every_sec = every_sec
        self._stop = threading.Event()
        self.t0 = time.time()
        self._frames = ["|", "/", "-", "\\"]

    def stop(self):
        self._stop.set()

    def run(self):
        i = 0
        while not self._stop.is_set():
            elapsed = int(time.time() - self.t0)
            frame = self._frames[i % len(self._frames)]
            msg = f"\\r{self.prefix} {frame}  elapsed={elapsed}s"
            try:
                sys.stdout.write(msg)
                sys.stdout.flush()
            except Exception:
                pass
            i += 1
            time.sleep(self.every_sec)
        try:
            sys.stdout.write("\\r" + " " * (len(self.prefix) + 60) + "\\r")
            sys.stdout.flush()
        except Exception:
            pass


def _create_session(
    name: str,
    model_path: Path,
    providers: List[str],
    provider_options: Optional[List[dict]],
    sess_options: ort.SessionOptions,
) -> Tuple[ort.InferenceSession, SessionBuildInfo]:
    spin = _Spinner(prefix=f"[init] building '{name}' (TensorRT build can take minutes)")
    t0 = time.time()
    spin.start()
    try:
        sess = ort.InferenceSession(
            str(model_path),
            sess_options=sess_options,
            providers=providers,
            provider_options=provider_options,
        )
    finally:
        spin.stop()
        spin.join(timeout=0.2)
    dt = time.time() - t0
    info = SessionBuildInfo(
        name=name,
        model_path=str(model_path),
        build_seconds=float(dt),
        providers_requested=list(providers),
        providers_in_use=list(sess.get_providers()),
    )
    print(f"[init] session '{name}' ready in {dt:.1f}s | providers in use: {info.providers_in_use}")
    return sess, info


# ----------------------------
# Hailo runtime (HEF) helpers
# ----------------------------


def _is_hailo_provider(p: str) -> bool:
    p = (p or "").lower().strip()
    # Hailo DFC uses `hw_arch` strings such as:
    #   hailo8, hailo8l, hailo8r, hailo10, hailo10h
    # Accept all known variants so a benchmark plan can refer to the exact
    # hardware architecture that was used to generate the HEF.
    return p in {"hailo8", "hailo8l", "hailo8r", "hailo10", "hailo10h"}


def _nchw_to_hwc_u8(x: np.ndarray) -> np.ndarray:
    """Convert NCHW/NHWC float/uint input to HWC uint8.

    Used for feeding quantized Hailo inputs.
    Heuristic: if max(x) <= 1.5 => treat as 0..1 and scale to 0..255.
    """
    arr = np.asarray(x)
    if arr.ndim == 4 and arr.shape[0] == 1:
        arr = arr[0]

    # NCHW -> HWC (common for ORT inputs)
    if arr.ndim == 3 and arr.shape[0] in (1, 3) and arr.shape[-1] not in (1, 3):
        arr = np.transpose(arr, (1, 2, 0))

    if arr.ndim != 3:
        raise ValueError(f"Expected 3D image tensor after squeeze/transpose, got shape {arr.shape}")

    if np.issubdtype(arr.dtype, np.floating):
        mx = float(np.nanmax(arr))
        if mx <= 1.5:
            arr = arr * 255.0
        arr = np.clip(arr, 0.0, 255.0).astype(np.uint8)
    else:
        arr = np.clip(arr, 0, 255).astype(np.uint8)
    return arr


def _ensure_frames_dim(x: np.ndarray) -> np.ndarray:
    """Ensure a leading frames dimension for Hailo InferVStreams."""
    if x.ndim == 3:
        return np.expand_dims(x, axis=0)
    return x


def _adapt_tensor(x: np.ndarray, target_shape: Tuple[int, ...]) -> np.ndarray:
    """Best-effort adaptation of a tensor to a target shape.

    Commonly needed when bridging between ORT (often NCHW) and Hailo vstreams
    (often HWC / NHWC).
    """
    arr = np.asarray(x)
    tgt = tuple(int(v) for v in target_shape)

    if tuple(arr.shape) == tgt:
        return arr

    # Remove batch / frames dim.
    if arr.ndim == 4 and arr.shape[0] == 1 and tuple(arr.shape[1:]) == tgt:
        return arr[0]
    if arr.ndim == 4 and arr.shape[0] == 1 and len(tgt) == 3 and tuple(arr.shape[1:]) == tgt:
        return arr[0]

    # Add batch dim (rare).
    if arr.ndim == 3 and len(tgt) == 4 and tgt[0] == 1 and tuple(arr.shape) == tgt[1:]:
        return arr[None, ...]

    # CHW <-> HWC
    if arr.ndim == 3 and len(tgt) == 3:
        # HWC -> CHW
        if arr.shape[-1] == 3 and tgt[0] == 3 and tgt[1] == arr.shape[0] and tgt[2] == arr.shape[1]:
            return np.transpose(arr, (2, 0, 1))
        # CHW -> HWC
        if arr.shape[0] == 3 and tgt[-1] == 3 and tgt[0] == arr.shape[1] and tgt[1] == arr.shape[2]:
            return np.transpose(arr, (1, 2, 0))

    # NCHW <-> NHWC (with batch)
    if arr.ndim == 4 and len(tgt) == 4:
        # NCHW -> NHWC
        if arr.shape[1] == 3 and tgt[-1] == 3 and tgt[0] == arr.shape[0] and tgt[1] == arr.shape[2] and tgt[2] == arr.shape[3]:
            return np.transpose(arr, (0, 2, 3, 1))
        # NHWC -> NCHW
        if arr.shape[-1] == 3 and tgt[1] == 3 and tgt[0] == arr.shape[0] and tgt[2] == arr.shape[1] and tgt[3] == arr.shape[2]:
            return np.transpose(arr, (0, 3, 1, 2))

    # As a last resort, try reshape if the total element count matches.
    try:
        if int(np.prod(arr.shape)) == int(np.prod(tgt)):
            return np.reshape(arr, tgt)
    except Exception:
        pass

    raise ValueError(f"Cannot adapt tensor from shape {tuple(arr.shape)} to target shape {tgt}")


def _map_inputs_to_outputs(expected_inputs: List[str], produced_outputs: List[str]) -> Dict[str, str]:
    """Map expected input names to produced output names.

    Strategy:
    - If names match exactly, use that.
    - If only one input and one output exist, map them.
    - Otherwise, map by suffix match or by order as a fallback.
    """
    mapping: Dict[str, str] = {}

    prod_set = set(produced_outputs)
    for inp in expected_inputs:
        if inp in prod_set:
            mapping[inp] = inp

    if len(mapping) == len(expected_inputs):
        return mapping

    if len(expected_inputs) == 1 and len(produced_outputs) == 1:
        return {expected_inputs[0]: produced_outputs[0]}

    # Suffix match fallback
    for inp in expected_inputs:
        if inp in mapping:
            continue
        cands = [o for o in produced_outputs if o.endswith(inp) or inp.endswith(o)]
        if len(cands) == 1:
            mapping[inp] = cands[0]

    # Order fallback
    if len(mapping) < len(expected_inputs):
        for i, inp in enumerate(expected_inputs):
            if inp in mapping:
                continue
            if i < len(produced_outputs):
                mapping[inp] = produced_outputs[i]

    return mapping


class HailoSession:
    """Reusable Hailo runtime wrapper around InferVStreams.

    Keeps VDevice + network group + InferVStreams open across runs so that timings
    measure inference, not setup.
    """

    def __init__(self, hef_path: Path, *, quantized_inputs: bool, quantized_outputs: bool):
        self.hef_path = Path(hef_path)
        self.quantized_inputs = bool(quantized_inputs)
        self.quantized_outputs = bool(quantized_outputs)

        try:
            import hailo_platform as hpf  # type: ignore
        except Exception as e:
            raise RuntimeError(
                "Hailo backend requested, but 'hailo_platform' is not importable. "
                "Install HailoRT + Python bindings on the target."
            ) from e

        self._hpf = hpf
        self._vdevice = None
        self._pipe = None
        self._network_group = None
        self._input_names: List[str] = []
        self._output_names: List[str] = []
        self.input_shapes: Dict[str, Tuple[int, ...]] = {}
        self.output_shapes: Dict[str, Tuple[int, ...]] = {}
        self._open()

    @property
    def input_names(self) -> List[str]:
        return list(self._input_names)

    @property
    def output_names(self) -> List[str]:
        return list(self._output_names)

    def _open(self) -> None:
        hpf = self._hpf
        if not self.hef_path.exists():
            raise FileNotFoundError(f"HEF not found: {self.hef_path}")

        hef = hpf.HEF(str(self.hef_path))

        # Keep VDevice open.
        self._vdevice = hpf.VDevice()
        try:
            if hasattr(self._vdevice, "__enter__"):
                self._vdevice.__enter__()
        except Exception:
            pass

        cfg_params = hpf.ConfigureParams.create_from_hef(hef, interface=hpf.HailoStreamInterface.PCIe)
        ngs = self._vdevice.configure(hef, cfg_params)
        if not ngs:
            raise RuntimeError("No network groups returned from VDevice.configure")
        self._network_group = ngs[0]

        # Activate.
        ng_params = self._network_group.create_params()
        self._network_group.activate(ng_params)

        self._input_names = [i.name for i in hef.get_input_vstream_infos()]
        self._output_names = [o.name for o in hef.get_output_vstream_infos()]
        self.input_shapes = {i.name: tuple(i.shape) for i in hef.get_input_vstream_infos()}
        self.output_shapes = {o.name: tuple(o.shape) for o in hef.get_output_vstream_infos()}

        in_params = hpf.InputVStreamParams.make(self._network_group, quantized=self.quantized_inputs, format_type=hpf.FormatType.AUTO)
        out_params = hpf.OutputVStreamParams.make(self._network_group, quantized=self.quantized_outputs, format_type=hpf.FormatType.AUTO)
        self._pipe = hpf.InferVStreams(self._network_group, in_params, out_params)
        self._pipe.__enter__()

    def close(self) -> None:
        try:
            if self._pipe is not None and hasattr(self._pipe, "__exit__"):
                self._pipe.__exit__(None, None, None)
        finally:
            self._pipe = None
        try:
            if self._vdevice is not None and hasattr(self._vdevice, "__exit__"):
                self._vdevice.__exit__(None, None, None)
        finally:
            self._vdevice = None

    def infer(self, inputs: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        if self._pipe is None:
            raise RuntimeError("HailoSession is closed")

        in_dict: Dict[str, np.ndarray] = {}
        for name in self._input_names:
            if name not in inputs:
                raise KeyError(f"Missing Hailo input '{name}'. Provided keys: {list(inputs.keys())}")
            in_dict[name] = _ensure_frames_dim(np.asarray(inputs[name]))

        outs = self._pipe.infer(in_dict)
        out_dict: Dict[str, np.ndarray] = {}
        for k, v in outs.items():
            arr = np.asarray(v)
            # Remove frames dim when present.
            if arr.ndim >= 1 and arr.shape[0] == 1:
                try:
                    arr = np.squeeze(arr, axis=0)
                except Exception:
                    pass
            out_dict[str(k)] = arr
        return out_dict

    def __enter__(self) -> "HailoSession":
        return self

    def __exit__(self, exc_type, exc, tb) -> None:
        self.close()


# ----------------------------
# ONNX IO helpers
# ----------------------------
def _get_initializer_names(model: onnx.ModelProto) -> set:
    names = set()
    for t in model.graph.initializer:
        if t.name:
            names.add(t.name)
    for t in getattr(model.graph, "sparse_initializer", []):
        if t.name:
            names.add(t.name)
    return names


def _get_non_initializer_inputs(model: onnx.ModelProto) -> List[onnx.ValueInfoProto]:
    init_names = _get_initializer_names(model)
    return [vi for vi in model.graph.input if vi.name not in init_names]


def _np_dtype_from_onnx(elem_type: int) -> np.dtype:
    # Compatible across ONNX versions (onnx.mapping moved/changed).
    try:
        from onnx import helper as onnx_helper
        return np.dtype(onnx_helper.tensor_dtype_to_np_dtype(elem_type))
    except Exception:
        try:
            tp = onnx.TensorProto
            m = {
                tp.FLOAT: np.float32,
                tp.FLOAT16: np.float16,
                tp.DOUBLE: np.float64,
                tp.INT64: np.int64,
                tp.INT32: np.int32,
                tp.INT16: np.int16,
                tp.INT8: np.int8,
                tp.UINT64: np.uint64,
                tp.UINT32: np.uint32,
                tp.UINT16: np.uint16,
                tp.UINT8: np.uint8,
                tp.BOOL: np.bool_,
            }
            return np.dtype(m.get(int(elem_type), np.float32))
        except Exception:
            return np.float32


def _shape_from_value_info(vi: onnx.ValueInfoProto) -> List[Optional[int]]:
    shape = []
    try:
        dims = vi.type.tensor_type.shape.dim
        for d in dims:
            if d.HasField("dim_value"):
                shape.append(int(d.dim_value))
            else:
                shape.append(None)
    except Exception:
        return []
    return shape


def _parse_shape_override(s: Optional[str]) -> Dict[str, Tuple[int, ...]]:
    out: Dict[str, Tuple[int, ...]] = {}
    if not s:
        return out
    # "name=1x128 other=1x3x640x640"
    for chunk in s.replace(",", " ").split():
        if "=" not in chunk:
            continue
        name, val = chunk.split("=", 1)
        name = name.strip()
        val = val.strip().lower().replace("x", " ")
        dims = [int(x) for x in val.split() if x.strip().isdigit()]
        if name and dims:
            out[name] = tuple(dims)
    return out


def _make_random_inputs(
    model: onnx.ModelProto,
    batch: Optional[int],
    seed: int,
    shape_overrides: Dict[str, Tuple[int, ...]],
    only_names: Optional[List[str]] = None,
) -> Dict[str, np.ndarray]:
    rng = np.random.default_rng(seed)
    out: Dict[str, np.ndarray] = {}
    for vi in _get_non_initializer_inputs(model):
        name = vi.name
        if only_names is not None and name not in only_names:
            continue
        dtype = _np_dtype_from_onnx(vi.type.tensor_type.elem_type)
        shp = _shape_from_value_info(vi)
        if name in shape_overrides:
            shp = list(shape_overrides[name])
        # Replace unknown dims with defaults
        fixed = []
        for i, d in enumerate(shp):
            if d is None or d == 0:
                if i == 0:
                    fixed.append(int(batch) if batch else 1)
                else:
                    fixed.append(1)
            else:
                fixed.append(int(d))
        if not fixed:
            fixed = [int(batch) if batch else 1]
        if dtype == np.bool_:
            out[name] = (rng.random(fixed) > 0.5)
        elif np.issubdtype(dtype, np.integer):
            out[name] = rng.integers(low=0, high=2, size=fixed, dtype=dtype)
        else:
            out[name] = rng.standard_normal(size=fixed).astype(dtype)
    return out


def _save_npz(path: str, arrays: Dict[str, np.ndarray], meta: dict) -> None:
    payload = {k: v for k, v in arrays.items()}
    payload["__meta__"] = np.frombuffer(json.dumps(meta, ensure_ascii=False).encode("utf-8"), dtype=np.uint8)
    np.savez_compressed(path, **payload)


def _load_inputs_npz(path: str) -> Tuple[Dict[str, np.ndarray], Optional[dict]]:
    d = np.load(path, allow_pickle=False)
    out: Dict[str, np.ndarray] = {}
    meta = None
    for k in d.files:
        if k == "__meta__":
            try:
                meta = json.loads(bytes(d[k].tolist()).decode("utf-8"))
            except Exception:
                meta = None
            continue
        out[k] = d[k]
    return out, meta


# ----------------------------
# Image input helper (optional)
# ----------------------------
def _is_probably_image_input(shape: List[Optional[int]]) -> bool:
    # Expect NCHW: [N,3,H,W]
    if len(shape) != 4:
        return False
    c = shape[1]
    return (c == 3) or (c is None)


def _load_image_as_nchw(
    img_path: Path,
    *,
    target_hw: Tuple[int, int],
    dtype: np.dtype,
    scale: str,
) -> Optional[np.ndarray]:
    if Image is None:
        print("[warn] PIL not available -> cannot load image input; using random inputs.")
        return None
    try:
        img = Image.open(str(img_path)).convert("RGB")
    except Exception as e:
        print(f"[warn] failed to load image '{img_path}': {type(e).__name__}: {e}")
        return None

    w, h = target_hw[1], target_hw[0]
    try:
        img_rs = img.resize((w, h))
    except Exception:
        img_rs = img

    arr = np.array(img_rs, dtype=np.float32)  # HWC, 0..255
    arr = np.transpose(arr, (2, 0, 1))  # CHW
    arr = np.expand_dims(arr, axis=0)  # NCHW

    if scale == "raw":
        # 0..255
        pass
    elif scale == "norm":
        # 0..1
        arr = arr / 255.0
    elif scale == "imagenet":
        # 0..1 -> (x-mean)/std
        arr = arr / 255.0
        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32).reshape(1, 3, 1, 1)
        std = np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 3, 1, 1)
        arr = (arr - mean) / std
    elif scale == "clip":
        # 0..1 -> (x-mean)/std (CLIP)
        arr = arr / 255.0
        mean = np.array([0.48145466, 0.4578275, 0.40821073], dtype=np.float32).reshape(1, 3, 1, 1)
        std = np.array([0.26862954, 0.26130258, 0.27577711], dtype=np.float32).reshape(1, 3, 1, 1)
        arr = (arr - mean) / std
    else:
        # caller handles "auto"
        pass

    if np.issubdtype(dtype, np.floating):
        return arr.astype(dtype, copy=False)
    if np.issubdtype(dtype, np.integer):
        return np.clip(arr, 0, np.iinfo(dtype).max).astype(dtype)
    return arr.astype(dtype, copy=False)


# ----------------------------
# Interface dump
# ----------------------------
def _dump_interface_npz(
    mode: str,
    out_prefix: Optional[str],
    out_dir: Path,
    feeds_left: Dict[str, np.ndarray],
    feeds_right: Dict[str, np.ndarray],
    meta_base: dict,
) -> None:
    def nbytes(d: Dict[str, np.ndarray]) -> int:
        return int(sum(int(v.nbytes) for v in d.values()))

    left_b = nbytes(feeds_left)
    right_b = nbytes(feeds_right)

    def write_one(path: Path, arrays: Dict[str, np.ndarray], extra: dict):
        meta = dict(meta_base)
        meta.update(extra)
        _save_npz(str(path), arrays, meta)

    if out_prefix:
        p = Path(out_prefix)
        if not p.is_absolute():
            p = out_dir / p
        base = p
    else:
        base = out_dir / "interface"

    if mode == "either":
        p_left = base.with_name(base.name + "_left.npz")
        p_right = base.with_name(base.name + "_right.npz")
        write_one(p_left, feeds_left, {"which": "left", "total_nbytes": left_b})
        write_one(p_right, feeds_right, {"which": "right", "total_nbytes": right_b})
        print(f"[dump-interface] wrote {p_left} ({left_b/1024/1024:.3f} MiB)")
        print(f"[dump-interface] wrote {p_right} ({right_b/1024/1024:.3f} MiB)")
        return

    if mode == "min":
        mode = "left" if left_b <= right_b else "right"

    if mode == "left":
        p = base.with_suffix(".npz")
        write_one(p, feeds_left, {"which": "left", "total_nbytes": left_b})
        print(f"[dump-interface] wrote {p} ({left_b/1024/1024:.3f} MiB)")
        return

    if mode == "right":
        p = base.with_suffix(".npz")
        write_one(p, feeds_right, {"which": "right", "total_nbytes": right_b})
        print(f"[dump-interface] wrote {p} ({right_b/1024/1024:.3f} MiB)")
        return

    raise SystemExit(f"Invalid --dump-interface mode '{mode}'")


# ----------------------------
# Benchmark + report
# ----------------------------
def _bench(tag: str, fn, warmup: int, runs: int) -> Tuple[float, float, List[float]]:
    print(f"[{tag}] warmup: {warmup} runs (not measured)")
    for i in range(warmup):
        fn()
    print(f"[{tag}] measured: {runs} runs")
    times = []
    for i in range(runs):
        t0 = time.time()
        fn()
        dt = (time.time() - t0) * 1000.0
        times.append(dt)
        print(f"  run {i+1}/{runs}: {dt:.3f} ms")
    return float(np.mean(times)), float(np.std(times)), times


def _try_write_report_plots(out_dir: Path, report: dict) -> None:
    try:
        import matplotlib.pyplot as plt  # type: ignore
    except Exception:
        print("[viz] matplotlib not available -> skipping validation_report.png/.pdf")
        return

    def _num(x: Any, default: float = 0.0) -> float:
        try:
            if x is None:
                return default
            v = float(x)
            if not np.isfinite(v):
                return default
            return v
        except Exception:
            return default

    t = report.get("timing_ms", {})
    labels = ["full", "part1", "part2", "composed"]
    means = [_num(t.get("full_mean")), _num(t.get("part1_mean")), _num(t.get("part2_mean")), _num(t.get("composed_mean"))]
    stds = [_num(t.get("full_std")), _num(t.get("part1_std")), _num(t.get("part2_std")), _num(t.get("composed_std"))]

    try:
        fig = plt.figure(figsize=(8, 4))
        ax = fig.add_subplot(1, 1, 1)
        xs = np.arange(len(labels))
        ax.bar(xs, means, yerr=stds, capsize=4)
        ax.set_xticks(xs)
        ax.set_xticklabels(labels)
        ax.set_ylabel("Latency (ms)")
        passed = report.get("output_diff", {}).get("passed", True)
        ax.set_title(f"Split benchmark (PASS={passed})")
        ax.grid(True, axis="y", linestyle=":", linewidth=0.5)
        fig.tight_layout()

        p_png = out_dir / "validation_report.png"
        p_pdf = out_dir / "validation_report.pdf"
        fig.savefig(str(p_png), dpi=150)
        fig.savefig(str(p_pdf))
        plt.close(fig)
        print(f"Wrote {p_png} and .pdf")
        report.setdefault("artifacts", {})
        report["artifacts"]["validation_report_png"] = str(p_png.name)
        report["artifacts"]["validation_report_pdf"] = str(p_pdf.name)
    except Exception as e:
        print(f"[viz] failed to write report plots: {type(e).__name__}: {e}")


# ----------------------------
# YOLO decode + draw (optional)
# ----------------------------
_COCO80 = [
    "person","bicycle","car","motorcycle","airplane","bus","train","truck","boat","traffic light",
    "fire hydrant","stop sign","parking meter","bench","bird","cat","dog","horse","sheep","cow",
    "elephant","bear","zebra","giraffe","backpack","umbrella","handbag","tie","suitcase","frisbee",
    "skis","snowboard","sports ball","kite","baseball bat","baseball glove","skateboard","surfboard","tennis racket","bottle",
    "wine glass","cup","fork","knife","spoon","bowl","banana","apple","sandwich","orange",
    "broccoli","carrot","hot dog","pizza","donut","cake","chair","couch","potted plant","bed",
    "dining table","toilet","tv","laptop","mouse","remote","keyboard","cell phone","microwave","oven",
    "toaster","sink","refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush",
]


def _sigmoid(x: np.ndarray) -> np.ndarray:
    """Numerically stable sigmoid.

    Why:
      Using ``1/(1+exp(-x))`` directly can overflow for large negative ``x``
      (because ``-x`` becomes a large positive number). In practice this shows up
      as ``RuntimeWarning: overflow encountered in exp`` and can also introduce
      NaNs downstream.

    This implementation avoids overflow by splitting on the sign of ``x``:
      * x >= 0:  1 / (1 + exp(-x))     (safe because -x <= 0)
      * x <  0:  exp(x) / (1 + exp(x)) (safe because x < 0)

    Notes:
      We compute in float32 for speed/stability and return float32.
    """

    x_arr = np.asarray(x)
    x_f = x_arr.astype(np.float32, copy=False)

    out = np.empty_like(x_f, dtype=np.float32)
    pos = x_f >= 0

    # x >= 0 branch
    out[pos] = 1.0 / (1.0 + np.exp(-x_f[pos]))

    # x < 0 branch
    exp_x = np.exp(x_f[~pos])
    out[~pos] = exp_x / (1.0 + exp_x)

    return out


def _is_yolo_multiscale(outputs: List[np.ndarray]) -> bool:
    if len(outputs) != 3:
        return False
    for o in outputs:
        if not isinstance(o, np.ndarray):
            return False
        if o.ndim != 5:
            return False
        if o.shape[1] != 3:
            return False
        if o.shape[-1] < 6:
            return False
    return True


# Default YOLOv5/YOLOv7 anchors for 640 input (works well for many exported yolov7 models)
_YOLO_ANCHORS = [
    [(12, 16), (19, 36), (40, 28)],
    [(36, 75), (76, 55), (72, 146)],
    [(142, 110), (192, 243), (459, 401)],
]


def _nms(boxes: np.ndarray, scores: np.ndarray, iou_thr: float, max_det: int) -> List[int]:
    # boxes: Nx4 (x1,y1,x2,y2)
    if boxes.size == 0:
        return []
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    areas = (x2 - x1 + 1e-6) * (y2 - y1 + 1e-6)
    order = scores.argsort()[::-1]
    keep: List[int] = []
    while order.size > 0 and len(keep) < max_det:
        i = int(order[0])
        keep.append(i)
        if order.size == 1:
            break
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-6)
        inds = np.where(iou <= iou_thr)[0]
        order = order[inds + 1]
    return keep


def _decode_yolo(
    outs: List[np.ndarray],
    img_hw: Tuple[int, int],
    conf_thr: float,
    iou_thr: float,
    max_det: int,
) -> List[dict]:
    # outs: list of 3 arrays, each (B,3,H,W,5+nc)
    H_img, W_img = img_hw
    # Sort by grid size desc to match anchor groups
    outs_sorted = sorted(outs, key=lambda a: int(a.shape[2]) * int(a.shape[3]), reverse=True)

    all_boxes = []
    all_scores = []
    all_cls = []

    for si, p in enumerate(outs_sorted):
        p = p.astype(np.float32, copy=False)
        b, na, gh, gw, ch = p.shape
        nc = ch - 5
        if nc <= 0:
            continue

        # stride inferred from input size / grid size
        stride_w = W_img / float(gw)
        stride_h = H_img / float(gh)
        stride = float((stride_w + stride_h) * 0.5)

        anchors = np.array(_YOLO_ANCHORS[min(si, len(_YOLO_ANCHORS)-1)], dtype=np.float32).reshape(1, na, 1, 1, 2)

        yv, xv = np.meshgrid(np.arange(gh, dtype=np.float32), np.arange(gw, dtype=np.float32), indexing="ij")
        grid = np.stack((xv, yv), axis=-1).reshape(1, 1, gh, gw, 2)

        xy = _sigmoid(p[..., 0:2]) * 2.0 - 0.5
        wh = (_sigmoid(p[..., 2:4]) * 2.0) ** 2
        obj = _sigmoid(p[..., 4:5])
        cls_scores = _sigmoid(p[..., 5:])

        cls_id = np.argmax(cls_scores, axis=-1).astype(np.int32)
        cls_max = np.max(cls_scores, axis=-1, keepdims=True)
        conf = (obj * cls_max).squeeze(-1)

        # Filter
        mask = conf > conf_thr
        if not np.any(mask):
            continue

        xy = (xy + grid) * stride
        wh = wh * anchors

        # boxes in xywh -> xyxy
        x = xy[..., 0]
        y = xy[..., 1]
        w = wh[..., 0]
        h = wh[..., 1]
        x1 = x - w / 2.0
        y1 = y - h / 2.0
        x2 = x + w / 2.0
        y2 = y + h / 2.0

        sel_x1 = x1[mask]
        sel_y1 = y1[mask]
        sel_x2 = x2[mask]
        sel_y2 = y2[mask]
        sel_conf = conf[mask]
        sel_cls = cls_id[mask]

        boxes = np.stack([sel_x1, sel_y1, sel_x2, sel_y2], axis=1)
        all_boxes.append(boxes)
        all_scores.append(sel_conf)
        all_cls.append(sel_cls)

    if not all_boxes:
        return []

    boxes = np.concatenate(all_boxes, axis=0)
    scores = np.concatenate(all_scores, axis=0)
    cls_ids = np.concatenate(all_cls, axis=0)

    # NMS (class-agnostic for simplicity)
    keep = _nms(boxes, scores, iou_thr=iou_thr, max_det=max_det)
    dets = []
    for i in keep:
        c = int(cls_ids[i])
        dets.append(
            {
                "x1": float(boxes[i, 0]),
                "y1": float(boxes[i, 1]),
                "x2": float(boxes[i, 2]),
                "y2": float(boxes[i, 3]),
                "score": float(scores[i]),
                "class_id": c,
                "class_name": _COCO80[c] if 0 <= c < len(_COCO80) else str(c),
            }
        )
    return dets


def _yolo_plausibility(outputs: Sequence[np.ndarray], img_hw: Tuple[int, int], conf_thr: float, iou_thr: float, max_det: int) -> Tuple[int, float]:
    """Heuristic plausibility for YOLO outputs.

    Used only for *auto* image scaling (norm vs raw). This must never crash.
    If decoding or scoring fails, we return a very low score so the other option
    can win.

    Returns:
        (n, score)
    """

    try:
        dets = _decode_yolo(outputs, img_hw=img_hw, conf_thr=conf_thr, iou_thr=iou_thr, max_det=max_det)

        # Some forks might return numpy arrays or tuples instead of dicts.
        scores: List[float] = []

        if dets is None:
            return 0, -1e9

        if isinstance(dets, np.ndarray):
            # Expect shape [N, ...] with score at col 4 if present.
            try:
                n = int(dets.shape[0])
            except Exception:
                n = 0
            try:
                if dets.ndim >= 2 and dets.shape[1] > 4:
                    scores_arr = dets[:, 4]
                else:
                    scores_arr = dets.reshape(-1)
                avg = float(np.mean(scores_arr)) if scores_arr.size else 0.0
            except Exception:
                avg = 0.0
            # Prefer moderate number of detections and reasonable confidence
            penalty = 0.0
            if n > 200:
                penalty += (n - 200) * 5.0
            if n < 1:
                penalty += 100.0
            penalty += abs(n - 10) * 1.0
            return n, (avg * 100.0 - penalty)

        # Best-effort conversion to list
        if not isinstance(dets, (list, tuple)):
            dets = list(dets) if hasattr(dets, "__iter__") else []

        if not dets:
            return 0, -1e9

        for d in dets:
            if isinstance(d, dict):
                s = d.get("score", d.get("conf", 0.0))
                try:
                    scores.append(float(s))
                except Exception:
                    scores.append(0.0)
                continue

            if isinstance(d, (list, tuple, np.ndarray)):
                try:
                    arr = np.asarray(d).reshape(-1)
                    if arr.size >= 5:
                        scores.append(float(arr[4]))
                    elif arr.size:
                        scores.append(float(arr[-1]))
                    else:
                        scores.append(0.0)
                except Exception:
                    scores.append(0.0)
                continue

            try:
                scores.append(float(getattr(d, "score", 0.0)))
            except Exception:
                scores.append(0.0)

        n = len(scores)
        avg = float(np.mean(scores)) if n else 0.0

        penalty = 0.0
        if n > 200:
            penalty += (n - 200) * 5.0
        if n < 1:
            penalty += 100.0
        penalty += abs(n - 10) * 1.0
        return n, (avg * 100.0 - penalty)

    except Exception as e:
        print(f"[warn] YOLO plausibility probe failed: {e}")
        return 0, -1e9



def _detr_plausibility(dets: List[dict]) -> float:
    """Heuristic for choosing the right image normalization for DETR/YOLOS-like outputs."""
    if not dets:
        return -1e9
    scores = [float(d.get("score", 0.0)) for d in dets]
    scores.sort(reverse=True)
    topk = scores[:10]
    top_mean = float(np.mean(topk)) if topk else 0.0
    # Penalize too many detections (usually indicates wrong preprocessing)
    return top_mean - 0.01 * float(len(dets))


def _draw_dets(img_path: Path, dets: List[dict], out_path: Path, *, img_hw: Tuple[int, int]) -> None:
    if Image is None or ImageDraw is None:
        return
    try:
        img = Image.open(str(img_path)).convert("RGB")
        img = img.resize((img_hw[1], img_hw[0]))
        draw = ImageDraw.Draw(img)
        for d in dets:
            x1, y1, x2, y2 = d["x1"], d["y1"], d["x2"], d["y2"]
            draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0), width=2)
            txt = f'{d["class_name"]} {d["score"]:.2f}'
            draw.text((x1 + 2, y1 + 2), txt, fill=(255, 0, 0))
        img.save(str(out_path))
    except Exception as e:
        print(f"[viz] failed to draw detections: {type(e).__name__}: {e}")


def _maybe_yolo_viz(
    out_dir: Path,
    img_path: Optional[Path],
    img_hw: Optional[Tuple[int, int]],
    full_out: List[np.ndarray],
    comp_out: List[np.ndarray],
    conf_thr: float,
    iou_thr: float,
    max_det: int,
) -> dict:
    info = {"enabled": False}
    if img_path is None or img_hw is None:
        print("[viz] no image input -> skipping YOLO visualization")
        return info
    if not _is_yolo_multiscale(full_out) or not _is_yolo_multiscale(comp_out):
        return info

    print("[viz] YOLO output format: multiscale head (B,3,H,W,...)")
    dets_full = _decode_yolo(full_out, img_hw=img_hw, conf_thr=conf_thr, iou_thr=iou_thr, max_det=max_det)
    dets_comp = _decode_yolo(comp_out, img_hw=img_hw, conf_thr=conf_thr, iou_thr=iou_thr, max_det=max_det)

    p_json_full = out_dir / "detections_full.json"
    p_json_comp = out_dir / "detections_composed.json"
    _write_json(p_json_full, {"image": str(img_path.name), "detections": dets_full})
    _write_json(p_json_comp, {"image": str(img_path.name), "detections": dets_comp})

    p_img_full = out_dir / "detections_full.png"
    p_img_comp = out_dir / "detections_composed.png"
    _draw_dets(img_path, dets_full, p_img_full, img_hw=img_hw)
    _draw_dets(img_path, dets_comp, p_img_comp, img_hw=img_hw)

    if p_img_full.exists():
        print(f"Wrote {p_img_full}")
    if p_img_comp.exists():
        print(f"Wrote {p_img_comp}")
    print(f"Wrote {p_json_full.name} and {p_json_comp.name}")

    info = {
        "enabled": True,
        "image": str(img_path.name),
        "img_hw": list(img_hw),
        "full": {"count": len(dets_full), "json": p_json_full.name, "png": p_img_full.name},
        "composed": {"count": len(dets_comp), "json": p_json_comp.name, "png": p_img_comp.name},
        "params": {"conf_thr": conf_thr, "iou_thr": iou_thr, "max_det": max_det},
    }
    return info




# ----------------------------
# DETR/YOLOS-style postprocess (logits + pred_boxes)
# ----------------------------
def _is_detr_like(output_names: List[str], outputs: List[np.ndarray]) -> bool:
    # Heuristic: outputs contain logits (..,C) and boxes (..,4)
    if len(outputs) < 2:
        return False
    names = [str(n) for n in output_names]
    # Common HF/DETR names
    if ("logits" in names and "pred_boxes" in names):
        return True
    # Shape-based fallback
    shapes = [getattr(a, "shape", ()) for a in outputs]
    has_boxes = any(len(s) >= 2 and s[-1] == 4 for s in shapes)
    has_logits = any(len(s) >= 2 and s[-1] >= 10 for s in shapes)  # num classes usually >= 10
    return bool(has_boxes and has_logits)


def _softmax(x: np.ndarray, axis: int = -1) -> np.ndarray:
    x = x.astype(np.float32, copy=False)
    x = x - np.max(x, axis=axis, keepdims=True)
    e = np.exp(x)
    s = np.sum(e, axis=axis, keepdims=True)
    return e / (s + 1e-12)


def _load_labels(path: Optional[str]) -> Optional[List[str]]:
    if not path:
        return None
    try:
        p = Path(path)
        if not p.exists():
            return None
        lines = [ln.strip() for ln in p.read_text(encoding="utf-8", errors="ignore").splitlines()]
        lines = [ln for ln in lines if ln]
        return lines if lines else None
    except Exception:
        return None


def _decode_detr(
    output_names: List[str],
    outputs: List[np.ndarray],
    img_hw: Tuple[int, int],
    conf_thr: float,
    iou_thr: float,
    max_det: int,
    labels: Optional[List[str]] = None,
) -> List[dict]:
    """
    Decode end-to-end detector outputs.

    Supported layouts:
      A) logits (B,Q,C)/(Q,C) + boxes (B,Q,4)/(Q,4)
         - If C == (#labels + 1) -> DETR-style softmax with background class (NMS optional)
         - Else -> sigmoid / already-probabilities without background (RT-DETR / YOLOv10/YOLO26 end2end)
                This path is NMS-free by design (we keep top-k only).

      B) dets (B,Q,6)/(Q,6) where last dim is [x1,y1,x2,y2,score,cls]
         (common Ultralytics end-to-end ONNX export for YOLOv10/YOLO26).

    Boxes may be cxcywh or xyxy, normalized or absolute.
    Returned detections are in xyxy pixel coordinates (relative to the input image).
    """
    H, W = img_hw

    name2 = {n: outputs[i] for i, n in enumerate(output_names)}

    # --- Layout B: (Q,6) / (B,Q,6) ---
    det6 = None
    for n, a in name2.items():
        if isinstance(a, np.ndarray) and a.ndim in (2, 3) and a.shape[-1] == 6:
            det6 = a
            break
    if det6 is not None:
        a = det6[0] if det6.ndim == 3 else det6  # (Q,6)
        if a.size == 0:
            return []
        a = a.astype(np.float32, copy=False)
        boxes = a[:, 0:4]
        scores = a[:, 4].astype(np.float32, copy=False)
        cls = a[:, 5].astype(np.int64, copy=False)

        # filter + top-k
        keep = np.where(scores >= float(conf_thr))[0]
        if keep.size == 0:
            return []
        scores = scores[keep]
        cls = cls[keep]
        boxes = boxes[keep]

        if scores.size > max_det:
            order = np.argsort(scores)[::-1][:max_det]
            scores = scores[order]
            cls = cls[order]
            boxes = boxes[order]

        b_max = float(np.nanmax(boxes)) if boxes.size else 0.0
        norm = b_max <= 1.5

        # Assume xyxy for this layout.
        if norm:
            x1 = boxes[:, 0] * W
            y1 = boxes[:, 1] * H
            x2 = boxes[:, 2] * W
            y2 = boxes[:, 3] * H
        else:
            x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]

        x1 = np.clip(x1, 0.0, W - 1.0)
        y1 = np.clip(y1, 0.0, H - 1.0)
        x2 = np.clip(x2, 0.0, W - 1.0)
        y2 = np.clip(y2, 0.0, H - 1.0)
        # ensure ordering
        x1_, x2_ = np.minimum(x1, x2), np.maximum(x1, x2)
        y1_, y2_ = np.minimum(y1, y2), np.maximum(y1, y2)
        x1, x2, y1, y2 = x1_, x2_, y1_, y2_

        dets = []
        for i in range(scores.shape[0]):
            dets.append({
                "x1": float(x1[i]),
                "y1": float(y1[i]),
                "x2": float(x2[i]),
                "y2": float(y2[i]),
                "score": float(scores[i]),
                "class_id": int(cls[i]),
                "class_name": labels[int(cls[i])] if labels and 0 <= int(cls[i]) < len(labels) else f"cls{int(cls[i])}",
            })
        return dets

    # --- Layout A: logits + boxes ---
    logits = None
    boxes = None
    for n, a in name2.items():
        if not isinstance(a, np.ndarray):
            continue
        if a.ndim in (2, 3) and a.shape[-1] == 4:
            boxes = a
        elif a.ndim in (2, 3) and a.shape[-1] >= 10:
            logits = a

    if logits is None or boxes is None:
        return []

    l = logits[0] if logits.ndim == 3 else logits  # (Q,C)
    b = boxes[0] if boxes.ndim == 3 else boxes      # (Q,4)

    if l.ndim != 2 or b.ndim != 2 or b.shape[1] != 4:
        return []

    Q, C = l.shape

    # Decide whether there is an explicit background class (DETR style).
    has_background = False
    if labels is not None and C == (len(labels) + 1):
        has_background = True
    # Common DETR exports (COCO) sometimes have 91+1 or 80+1 classes.
    if labels is None and C in (81, 92):
        has_background = True

    # Compute class probabilities.
    if has_background:
        probs = _softmax(l.astype(np.float32, copy=False), axis=-1)
        probs = probs[:, :-1]  # drop background
    else:
        lf = l.astype(np.float32, copy=False)
        lmin = float(np.nanmin(lf)) if lf.size else 0.0
        lmax = float(np.nanmax(lf)) if lf.size else 0.0
        if 0.0 <= lmin and lmax <= 1.0:
            probs = lf  # already probabilities
        else:
            probs = _sigmoid(lf)

    # Best class per query (NMS-free models rely on low absolute scores for "no object" queries).
    cls = np.argmax(probs, axis=1).astype(np.int64)
    scores = probs[np.arange(Q), cls]

    keep = np.where(scores >= float(conf_thr))[0]
    if keep.size == 0:
        return []

    scores = scores[keep]
    cls = cls[keep]
    b = b[keep].astype(np.float32, copy=False)

    # Keep top-k by score (always).
    if scores.size > max_det:
        order = np.argsort(scores)[::-1][:max_det]
        scores = scores[order]
        cls = cls[order]
        b = b[order]

    # Determine whether boxes are normalized and whether they are xyxy or cxcywh.
    b_max = float(np.nanmax(b)) if b.size else 0.0
    norm = b_max <= 1.5

    # If columns look like x2>=x1 and y2>=y1 for almost all boxes, treat as xyxy.
    frac_xyxy = float(np.mean((b[:, 2] >= b[:, 0]) & (b[:, 3] >= b[:, 1]))) if b.size else 0.0
    box_mode = "xyxy" if frac_xyxy > 0.95 else "cxcywh"

    if norm:
        if box_mode == "xyxy":
            x1 = b[:, 0] * W
            y1 = b[:, 1] * H
            x2 = b[:, 2] * W
            y2 = b[:, 3] * H
        else:
            cx = b[:, 0] * W
            cy = b[:, 1] * H
            bw = b[:, 2] * W
            bh = b[:, 3] * H
            x1 = cx - 0.5 * bw
            y1 = cy - 0.5 * bh
            x2 = cx + 0.5 * bw
            y2 = cy + 0.5 * bh
    else:
        if box_mode == "xyxy":
            x1, y1, x2, y2 = b[:, 0], b[:, 1], b[:, 2], b[:, 3]
        else:
            cx, cy, bw, bh = b[:, 0], b[:, 1], b[:, 2], b[:, 3]
            x1 = cx - 0.5 * bw
            y1 = cy - 0.5 * bh
            x2 = cx + 0.5 * bw
            y2 = cy + 0.5 * bh

    x1 = np.clip(x1, 0.0, W - 1.0)
    y1 = np.clip(y1, 0.0, H - 1.0)
    x2 = np.clip(x2, 0.0, W - 1.0)
    y2 = np.clip(y2, 0.0, H - 1.0)
    # ensure ordering
    x1_, x2_ = np.minimum(x1, x2), np.maximum(x1, x2)
    y1_, y2_ = np.minimum(y1, y2), np.maximum(y1, y2)
    x1, x2, y1, y2 = x1_, x2_, y1_, y2_

    # Apply NMS only for explicit-background DETR style.
    if has_background and scores.size > 0 and float(iou_thr) < 0.999:
        keep_idx = _nms(np.stack([x1, y1, x2, y2], axis=1), scores, iou_thr=float(iou_thr), max_det=max_det)
        x1 = x1[keep_idx]
        y1 = y1[keep_idx]
        x2 = x2[keep_idx]
        y2 = y2[keep_idx]
        scores = scores[keep_idx]
        cls = cls[keep_idx]

    dets = []
    for i in range(scores.shape[0]):
        dets.append({
            "x1": float(x1[i]),
            "y1": float(y1[i]),
            "x2": float(x2[i]),
            "y2": float(y2[i]),
            "score": float(scores[i]),
            "class_id": int(cls[i]),
            "class_name": labels[int(cls[i])] if labels and 0 <= int(cls[i]) < len(labels) else f"cls{int(cls[i])}",
        })
    return dets

def _maybe_detr_viz(
    out_dir: Path,
    img_path: Optional[Path],
    img_hw: Optional[Tuple[int, int]],
    output_names: List[str],
    full_out: List[np.ndarray],
    comp_out: List[np.ndarray],
    conf_thr: float,
    iou_thr: float,
    max_det: int,
    labels: Optional[List[str]],
) -> dict:
    info = {"enabled": False}
    if img_path is None or img_hw is None:
        print("[viz] no image input -> skipping DETR visualization")
        return info
    if not _is_detr_like(output_names, full_out) or not _is_detr_like(output_names, comp_out):
        return info

    print("[viz] DETR/YOLOS output format: logits + pred_boxes")
    dets_full = _decode_detr(output_names, full_out, img_hw=img_hw, conf_thr=conf_thr, iou_thr=iou_thr, max_det=max_det, labels=labels)
    dets_comp = _decode_detr(output_names, comp_out, img_hw=img_hw, conf_thr=conf_thr, iou_thr=iou_thr, max_det=max_det, labels=labels)

    p_json_full = out_dir / "detections_full.json"
    p_json_comp = out_dir / "detections_composed.json"
    _write_json(p_json_full, {"image": str(img_path.name), "detections": dets_full})
    _write_json(p_json_comp, {"image": str(img_path.name), "detections": dets_comp})

    p_img_full = out_dir / "detections_full.png"
    p_img_comp = out_dir / "detections_composed.png"
    _draw_dets(img_path, dets_full, p_img_full, img_hw=img_hw)
    _draw_dets(img_path, dets_comp, p_img_comp, img_hw=img_hw)

    if p_img_full.exists():
        print(f"Wrote {p_img_full}")
    if p_img_comp.exists():
        print(f"Wrote {p_img_comp}")
    print(f"Wrote {p_json_full.name} and {p_json_comp.name}")

    info = {
        "enabled": True,
        "image": str(img_path.name),
        "img_hw": list(img_hw),
        "full": {"count": len(dets_full), "json": p_json_full.name, "png": p_img_full.name},
        "composed": {"count": len(dets_comp), "json": p_json_comp.name, "png": p_img_comp.name},
        "params": {"conf_thr": conf_thr, "iou_thr": iou_thr, "max_det": max_det},
    }
    return info


# ----------------------------
# Main
# ----------------------------
def main() -> int:
    ap = argparse.ArgumentParser(description="Run ORT benchmark for a split ONNX model set.")
    ap.add_argument("--manifest", type=str, default=DEFAULT_MANIFEST, help="Split manifest JSON (default from export).")
    ap.add_argument(
        "--provider",
        type=str,
        default=DEFAULT_PROVIDER,
        choices=["auto", "tensorrt", "cuda", "cpu", "hailo8", "hailo8l", "hailo8r", "hailo10", "hailo10h"],
        help="Backend preference (ORT: auto/tensorrt/cuda/cpu; Hailo: hailo8/hailo8l/hailo8r/hailo10/hailo10h).",
    )
    ap.add_argument("--out-dir", type=str, default="results", help="Output dir for reports (default: results/)")
    ap.add_argument("--warmup", type=int, default=5, help="Warmup runs per benchmark")
    ap.add_argument("--runs", type=int, default=10, help="Measured runs per benchmark")
    ap.add_argument("--eps", type=float, default=1e-4, help="Max-abs threshold for output diff PASS/FAIL")
    ap.add_argument("--seed", type=int, default=0, help="RNG seed for random input generation")
    ap.add_argument("--batch", type=int, default=None, help="Batch dim for random input generation (if dim0 unknown)")
    ap.add_argument("--shape-override", type=str, default=None, help="Override input shapes for random generation, shorthand: name=1x128;other=1x3x640x640")
    ap.add_argument("--inputs-npz", type=str, default=None, help="Load model inputs from an .npz file (keys are input names). Missing inputs are generated.")
    ap.add_argument("--save-inputs-npz", type=str, default=None, help="Save the final full-model input feed dict to an .npz file (includes __meta__).")

    # Image helper (for CV models)
    ap.add_argument("--image", type=str, default="test_image.png", help="Optional image file for CV inputs (default: test_image.png)")
    ap.add_argument("--image-scale", type=str, default="auto", choices=["auto", "norm", "raw", "imagenet", "clip"], help="Image preprocessing for float inputs: raw=0..255, norm=img/255, imagenet=(img/255-mean)/std, clip=CLIP norm, auto=probe (YOLO/DETR)")

    # Visualization
    ap.add_argument("--viz", type=str, default="auto", choices=["auto", "none", "yolo", "detr"], help="Visualization: auto (YOLO/DETR if detected), yolo, detr, none")
    ap.add_argument("--no-report-plots", action="store_true", help="Disable validation_report.png/.pdf generation")
    ap.add_argument("--yolo-conf", type=float, default=0.25, help="YOLO confidence threshold")
    ap.add_argument("--yolo-iou", type=float, default=0.45, help="YOLO NMS IoU threshold")
    ap.add_argument("--yolo-max-det", type=int, default=200, help="YOLO max detections after NMS")
    ap.add_argument("--detr-conf", type=float, default=0.25, help="DETR/YOLOS confidence threshold")
    ap.add_argument("--detr-iou", type=float, default=0.50, help="DETR/YOLOS NMS IoU threshold")
    ap.add_argument("--detr-max-det", type=int, default=200, help="DETR/YOLOS max detections after NMS")
    ap.add_argument("--labels", type=str, default=None, help="Optional label file (one class name per line) for visualization")

    # Interface dump
    ap.add_argument("--dump-interface", type=str, default=None, choices=["right", "left", "min", "either"], help="Dump interface NPZ(s): right=part2 feed, left=part1 feed, either=both, min=smaller.")
    ap.add_argument("--dump-interface-out", type=str, default=None, help="Output path/prefix for interface NPZ(s). Default: <out-dir>/interface_*.npz")

    # Session options
    ap.add_argument("--build-only", action="store_true", help="Only build sessions/engines, run 1 inference each, exit.")
    ap.add_argument("--ort-log-severity", type=int, default=2, help="ORT log severity (0=verbose,1=info,2=warning,3=error,4=fatal).")

    # TRT options
    ap.add_argument("--trt-cache-dir", type=str, default="trt_cache", help="TensorRT engine cache directory")
    ap.add_argument("--trt-cache", dest="trt_cache", action="store_true", default=True, help="Enable engine cache")
    ap.add_argument("--no-trt-cache", dest="trt_cache", action="store_false", help="Disable engine cache")
    ap.add_argument("--trt-fp16", action="store_true", help="Enable TRT FP16")
    ap.add_argument("--trt-dump-subgraphs", action="store_true", help="Enable TRT subgraph dump (ORT TensorRT EP)")
    ap.add_argument("--trt-fast-build", action="store_true", help="Faster TRT build preset (opt level 2)")

    args = ap.parse_args()

    base_dir = Path(__file__).resolve().parent
    manifest_path = Path(args.manifest)
    if not manifest_path.is_absolute():
        manifest_path = base_dir / manifest_path
    if not manifest_path.exists():
        raise SystemExit(f"Manifest not found: {manifest_path}")

    out_dir = Path(args.out_dir)
    if not out_dir.is_absolute():
        out_dir = base_dir / out_dir
    out_dir.mkdir(parents=True, exist_ok=True)

    manifest = _read_json(manifest_path)

    # Manifest schema compatibility
    full_rel = manifest.get("full_model") or manifest.get("full") or manifest.get("model")
    p1_rel = manifest.get("part1_model") or manifest.get("part1") or manifest.get("part1_path")
    p2_rel = manifest.get("part2_model") or manifest.get("part2") or manifest.get("part2_path")
    if not full_rel or not p1_rel or not p2_rel:
        raise SystemExit(
            "Manifest schema not recognized. Expected keys like "
            "'full_model' and ('part1'/'part1_model') and ('part2'/'part2_model'). "
            f"Found keys: {sorted(manifest.keys())}"
        )

    full_path = Path(full_rel)
    p1_path = Path(p1_rel)
    p2_path = Path(p2_rel)
    if not full_path.is_absolute():
        full_path = base_dir / full_path
    if not p1_path.is_absolute():
        p1_path = base_dir / p1_path
    if not p2_path.is_absolute():
        p2_path = base_dir / p2_path

    print(f"[info] manifest: {manifest_path}")
    print(f"[info] full : {full_path.name}")
    print(f"[info] part1: {p1_path.name}")
    print(f"[info] part2: {p2_path.name}")

    # Load only the ONNX skeleton (avoid pulling huge external weights into RAM)
    full_model = onnx.load(str(full_path), load_external_data=False)

    shape_overrides = _parse_shape_override(args.shape_override)

    feeds_full: Dict[str, np.ndarray] = {}
    loaded_inputs_meta = None
    if args.inputs_npz:
        feeds_full, loaded_inputs_meta = _load_inputs_npz(args.inputs_npz)
        print(f"[inputs] loaded {len(feeds_full)} tensor(s) from {args.inputs_npz}")

    required_inputs = [vi.name for vi in _get_non_initializer_inputs(full_model)]
    missing = [n for n in required_inputs if n not in feeds_full]

    # Optional: use image for missing CV input(s)
    img_path = None
    img_hw = None
    img_candidates = None  # type: ignore
    if missing and not args.inputs_npz and args.image:
        p_img = Path(args.image)
        if not p_img.is_absolute():
            p_img = base_dir / p_img
        if p_img.exists():
            # Find first image-like input among missing
            for vi in _get_non_initializer_inputs(full_model):
                if vi.name not in missing:
                    continue
                shp = _shape_from_value_info(vi)
                if vi.name in shape_overrides:
                    shp = list(shape_overrides[vi.name])
                if not _is_probably_image_input(shp):
                    continue
                dtype = _np_dtype_from_onnx(vi.type.tensor_type.elem_type)
                # Determine H,W
                H = int(shp[2]) if shp[2] else 640
                W = int(shp[3]) if shp[3] else 640
                img_hw = (H, W)
                img_path = p_img
                if args.image_scale == "auto":
                    img_candidates = {
                        "raw": _load_image_as_nchw(p_img, target_hw=img_hw, dtype=dtype, scale="raw"),
                        "norm": _load_image_as_nchw(p_img, target_hw=img_hw, dtype=dtype, scale="norm"),
                        "imagenet": _load_image_as_nchw(p_img, target_hw=img_hw, dtype=dtype, scale="imagenet"),
                        "clip": _load_image_as_nchw(p_img, target_hw=img_hw, dtype=dtype, scale="clip"),
                        "name": vi.name,
                    }
                    # default to norm
                    if img_candidates.get("norm") is not None:
                        feeds_full[vi.name] = img_candidates["norm"]
                        missing.remove(vi.name)
                else:
                    arr = _load_image_as_nchw(p_img, target_hw=img_hw, dtype=dtype, scale=args.image_scale)
                    if arr is not None:
                        feeds_full[vi.name] = arr
                        missing.remove(vi.name)
                if vi.name in feeds_full:
                    print(f"[inputs] using image '{p_img.name}' for input '{vi.name}' shape={list(feeds_full[vi.name].shape)} scale={args.image_scale}")
                    break

    if missing:
        feeds_full.update(
            _make_random_inputs(
                full_model,
                batch=args.batch,
                seed=args.seed,
                shape_overrides=shape_overrides,
                only_names=missing,
            )
        )
        if args.inputs_npz:
            print(f"[inputs] generated {len(missing)} missing input(s): {missing[:8]}{'...' if len(missing)>8 else ''}")

    if args.save_inputs_npz:
        meta = {
            "format": "model_inputs_npz_v1",
            "created": _now_ts(),
            "created_time_unix": time.time(),
            "manifest": str(manifest_path.name),
            "shape_override": args.shape_override,
            "loaded_meta": loaded_inputs_meta,
            "inputs": {k: {"shape": list(v.shape), "dtype": str(v.dtype), "nbytes": int(v.nbytes)} for k, v in feeds_full.items()},
        }
        out_npz = Path(args.save_inputs_npz)
        if not out_npz.is_absolute():
            out_npz = out_dir / out_npz
        _save_npz(str(out_npz), feeds_full, meta)
        print(f"[inputs] wrote {out_npz} (tensors={len(feeds_full)})")

    req_provider = str(args.provider or "auto").lower().strip()
    hailo_hw = req_provider if _is_hailo_provider(req_provider) else ""

    avail = _available_providers()
    print(f"ORT available providers: {avail}")

    # If a Hailo backend is requested, we still use ORT (CPU) for baseline outputs
    # and for graph metadata (names/shapes). Timings are taken from Hailo.
    ort_provider_hint = "cpu" if hailo_hw else req_provider
    providers = _pick_providers(ort_provider_hint, avail)
    if hailo_hw:
        print(f"Using Hailo backend: {hailo_hw} (ORT baseline: {providers})")
    else:
        print(f"Using providers: {providers}")

    sess_options = ort.SessionOptions()
    sess_options.log_severity_level = int(args.ort_log_severity)

    provider_options: Optional[List[dict]] = None
    if "TensorrtExecutionProvider" in providers:
        cache_dir = Path(args.trt_cache_dir)
        if not cache_dir.is_absolute():
            cache_dir = base_dir / cache_dir
        cache_dir.mkdir(parents=True, exist_ok=True)
        print(f"[tensorrt] engine cache dir: {cache_dir}")

        trt_opts = {
            "trt_engine_cache_enable": _as_ort_opt(bool(args.trt_cache)),
            "trt_engine_cache_path": str(cache_dir),
            "trt_timing_cache_enable": _as_ort_opt(bool(args.trt_cache)),
            "trt_timing_cache_path": str(cache_dir / "timing.cache"),
            "trt_fp16_enable": _as_ort_opt(bool(args.trt_fp16)),
            "trt_dump_subgraphs": _as_ort_opt(bool(args.trt_dump_subgraphs)),
        }
        if args.trt_fast_build:
            trt_opts["trt_builder_optimization_level"] = _as_ort_opt(2)
            trt_opts["trt_build_heuristics_enable"] = _as_ort_opt(True)

        provider_options = []
        for p in providers:
            provider_options.append(trt_opts if p == "TensorrtExecutionProvider" else {})

    sess_full, info_full = _create_session("full", full_path, providers, provider_options, sess_options)
    sess_p1, info_p1 = _create_session("part1", p1_path, providers, provider_options, sess_options)
    sess_p2, info_p2 = _create_session("part2", p2_path, providers, provider_options, sess_options)

    # If image_scale=auto, try to pick a sane preprocessing preset.
    if img_candidates is not None and args.image_scale == "auto":
        out_names = [o.name for o in sess_full.get_outputs()]

        def _run_full_with_scale(scale: str):
            feeds = dict(feeds_full)
            feeds[img_candidates["name"]] = img_candidates[scale]
            return sess_full.run(None, feeds)

        # Probe using "norm" once to identify output family (YOLO vs DETR-like vs unknown)
        out_norm = _run_full_with_scale("norm")

        if _is_yolo_multiscale(out_norm):
            print("[auto] Probing YOLO input scaling (norm vs raw)...")
            out_raw = _run_full_with_scale("raw")
            n_norm, p_norm = _yolo_plausibility(out_norm, img_hw, args.yolo_conf, args.yolo_iou, args.yolo_max_det)
            n_raw, p_raw = _yolo_plausibility(out_raw, img_hw, args.yolo_conf, args.yolo_iou, args.yolo_max_det)
            print(f"  image_scale=norm: {n_norm} dets, plausibility={p_norm:.1f}")
            print(f"  image_scale=raw : {n_raw} dets, plausibility={p_raw:.1f}")
            selected = "norm" if p_norm >= p_raw else "raw"
            print(f"[auto] Selected image_scale={selected}.")
            feeds_full[img_candidates["name"]] = img_candidates[selected]

        elif _is_detr_like(out_norm, out_names):
            print("[auto] Probing DETR/YOLOS input normalization (imagenet/norm/raw/clip)...")
            cand_order = ["imagenet", "norm", "raw", "clip"]
            best_scale = None
            best_plaus = -1e9
            for sc in cand_order:
                if sc not in img_candidates:
                    continue
                out_sc = out_norm if sc == "norm" else _run_full_with_scale(sc)
                dets = _decode_detr(
                    out_sc,
                    out_names,
                    img_hw=img_hw,
                    conf_thr=args.viz_conf,
                    iou_thr=args.viz_iou,
                    max_det=args.viz_max_det,
                )
                plaus = _detr_plausibility(dets)
                print(f"  image_scale={sc:8s}: {len(dets)} dets, plausibility={plaus:.3f}")
                if plaus > best_plaus:
                    best_plaus = plaus
                    best_scale = sc
            if best_scale is None:
                best_scale = "norm"
            print(f"[auto] Selected image_scale={best_scale}.")
            feeds_full[img_candidates["name"]] = img_candidates.get(best_scale, img_candidates["norm"])
        else:
            print("[auto] image_scale=auto -> defaulting to norm (unknown outputs).")
            feeds_full[img_candidates["name"]] = img_candidates["norm"]

    # Build feeds for part1/part2
    p1_inputs = [i.name for i in sess_p1.get_inputs()]
    feeds_p1: Dict[str, np.ndarray] = {}
    missing_p1: List[str] = []
    for name in p1_inputs:
        if name in feeds_full:
            feeds_p1[name] = feeds_full[name]
        else:
            missing_p1.append(name)
    if missing_p1:
        raise SystemExit(f"Missing inputs for part1: {missing_p1}")

    p1_out0 = sess_p1.run(None, feeds_p1)
    p1_map0: Dict[str, np.ndarray] = {o.name: a for o, a in zip(sess_p1.get_outputs(), p1_out0)}

    p2_inputs = [i.name for i in sess_p2.get_inputs()]
    missing_p2 = [n for n in p2_inputs if (n not in p1_map0 and n not in feeds_full)]
    if missing_p2:
        raise SystemExit(f"Missing inputs for part2 (neither cut tensor nor in full inputs): {missing_p2}")

    def build_feeds_p2(p1_map: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        d: Dict[str, np.ndarray] = {}
        for n in p2_inputs:
            d[n] = p1_map[n] if n in p1_map else feeds_full[n]
        return d

    feeds_p2_0 = build_feeds_p2(p1_map0)

    if args.dump_interface:
        meta_base = {
            "format": "split_interface_npz_v1",
            "created": _now_ts(),
            "created_time_unix": time.time(),
            "manifest": str(manifest_path.name),
            "mode": args.dump_interface,
            "provider": args.provider,
            "providers_in_use": {"full": info_full.providers_in_use, "part1": info_p1.providers_in_use, "part2": info_p2.providers_in_use},
            "shape_override": args.shape_override,
            "inputs_npz": args.inputs_npz,
            "note": "NPZ keys are exact ORT input names. '__meta__' contains JSON metadata.",
            "left_inputs": {k: {"shape": list(v.shape), "dtype": str(v.dtype), "nbytes": int(v.nbytes)} for k, v in feeds_p1.items()},
            "right_inputs": {k: {"shape": list(v.shape), "dtype": str(v.dtype), "nbytes": int(v.nbytes)} for k, v in feeds_p2_0.items()},
        }
        _dump_interface_npz(args.dump_interface, args.dump_interface_out, out_dir, feeds_p1, feeds_p2_0, meta_base)

    if args.build_only:
        print("[build-only] running 1 inference(s) to finalize engine builds/caches...")
        _ = sess_full.run(None, feeds_full)
        _ = sess_p1.run(None, feeds_p1)
        _ = sess_p2.run(None, feeds_p2_0)
        report = {
            "created": _now_ts(),
            "manifest": str(manifest_path),
            "sessions": {"full": info_full.__dict__, "part1": info_p1.__dict__, "part2": info_p2.__dict__},
            "providers_available": avail,
            "providers_requested": providers,
            "note": "Build-only mode: no benchmarks/diffs.",
        }
        out_report = out_dir / "build_report.json"
        _write_json(out_report, report)
        print(f"[build-only] wrote {out_report}")
        print("[build-only] done.")
        return 0

    def run_full():
        return sess_full.run(None, feeds_full)

    # ----------------
    # ORT vs Hailo run
    # ----------------

    final_out_names = [o.name for o in sess_full.get_outputs()]

    hailo_p1: Optional[HailoSession] = None
    hailo_p2: Optional[HailoSession] = None

    def _order_out_map(out_map: Dict[str, np.ndarray]) -> List[np.ndarray]:
        # Primary: order like the full graph outputs.
        ordered = [out_map[n] for n in final_out_names if n in out_map]
        if ordered and len(ordered) == len(final_out_names):
            return ordered

        # Secondary: order like the right/part2 outputs.
        alt = [out_map[n] for n in [o.name for o in sess_p2.get_outputs()] if n in out_map]
        if alt:
            return alt

        # Fallback: deterministic order.
        return [out_map[k] for k in sorted(out_map.keys())]

    if hailo_hw:
        # Hailo HEFs are expected at: hailo/<hw_arch>/part{1|2}/compiled.hef
        # where <hw_arch> is e.g. hailo8, hailo8l, hailo10h, ...
        hef_root = base_dir / "hailo" / hailo_hw
        hef_p1 = hef_root / "part1" / "compiled.hef"
        hef_p2 = hef_root / "part2" / "compiled.hef"

        hailo_p1 = HailoSession(hef_p1, quantized_inputs=True, quantized_outputs=False)
        hailo_p2 = HailoSession(hef_p2, quantized_inputs=False, quantized_outputs=False)

        # Build Hailo stage1 inputs.
        p1_inputs_hailo: Dict[str, np.ndarray] = {}
        for name in hailo_p1.input_names:
            src = feeds_p1.get(name)
            if src is None:
                # Fallback: single-input models.
                src = next(iter(feeds_p1.values()))

            src_arr = np.asarray(src)
            # For image-like tensors we convert to uint8 and let Hailo quantization handle scaling.
            try:
                img_u8 = _nchw_to_hwc_u8(src_arr)
                tgt_shape = hailo_p1.input_shapes.get(name)
                if tgt_shape is not None:
                    img_u8 = _adapt_tensor(img_u8, tgt_shape)
                p1_inputs_hailo[name] = img_u8
            except Exception:
                # Non-image / already-quantized input
                tgt_shape = hailo_p1.input_shapes.get(name)
                p1_inputs_hailo[name] = _adapt_tensor(src_arr, tgt_shape) if tgt_shape is not None else src_arr

        def run_p1_map() -> Dict[str, np.ndarray]:
            assert hailo_p1 is not None
            return hailo_p1.infer(p1_inputs_hailo)

        # Precompute mapping and a fixed stage2 input tensor for benchmarking stage2 alone.
        p1_map0_h = run_p1_map()
        p2_in_map = _map_inputs_to_outputs(hailo_p2.input_names, list(p1_map0_h.keys()))

        def _build_p2_inputs_from_p1(out1_map: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
            assert hailo_p2 is not None
            d: Dict[str, np.ndarray] = {}
            for inp in hailo_p2.input_names:
                src_name = p2_in_map.get(inp, inp)
                if src_name in out1_map:
                    src = out1_map[src_name]
                elif inp in feeds_full:
                    src = feeds_full[inp]
                else:
                    raise KeyError(
                        f"Cannot build part2 input '{inp}': not in part1 outputs and not in full inputs. "
                        f"part1 outputs={list(out1_map.keys())} full inputs={list(feeds_full.keys())}"
                    )
                tgt_shape = hailo_p2.input_shapes.get(inp)
                if tgt_shape is not None:
                    src = _adapt_tensor(src, tgt_shape)
                d[inp] = src
            return d

        p2_inputs_hailo_0 = _build_p2_inputs_from_p1(p1_map0_h)

        def run_p2_map() -> Dict[str, np.ndarray]:
            assert hailo_p2 is not None
            return hailo_p2.infer(p2_inputs_hailo_0)

        def run_composed_map() -> Dict[str, np.ndarray]:
            out1 = run_p1_map()
            assert hailo_p2 is not None
            return hailo_p2.infer(_build_p2_inputs_from_p1(out1))

        # Timings: skip full (ORT baseline) for Hailo runs.
        print("[full] skipped timing (Hailo backend)")
        full_mean, full_std = None, None
        p1_mean, p1_std, _ = _bench("part1", run_p1_map, args.warmup, args.runs)
        p2_mean, p2_std, _ = _bench("part2", run_p2_map, args.warmup, args.runs)
        comp_mean, comp_std, _ = _bench("composed", run_composed_map, args.warmup, args.runs)

        # Outputs for diff/viz.
        full_out = run_full()
        comp_out = _order_out_map(run_composed_map())

    else:
        # Pure ORT path.
        def run_p1() -> List[np.ndarray]:
            return sess_p1.run(None, feeds_p1)

        def run_p2() -> List[np.ndarray]:
            return sess_p2.run(None, feeds_p2_0)

        def run_composed() -> List[np.ndarray]:
            out_p1 = sess_p1.run(None, feeds_p1)
            p1_map = {o.name: a for o, a in zip(sess_p1.get_outputs(), out_p1)}
            return sess_p2.run(None, build_feeds_p2(p1_map))

        full_mean, full_std, _ = _bench("full", run_full, args.warmup, args.runs)
        p1_mean, p1_std, _ = _bench("part1", run_p1, args.warmup, args.runs)
        p2_mean, p2_std, _ = _bench("part2", run_p2, args.warmup, args.runs)
        comp_mean, comp_std, _ = _bench("composed", run_composed, args.warmup, args.runs)

        full_out = run_full()
        comp_out = run_composed()

    n = min(len(full_out), len(comp_out))
    per_out = []
    max_abs_global = 0.0
    mean_abs_global = 0.0
    if n > 0:
        for i in range(n):
            a = full_out[i]
            b = comp_out[i]
            da = a.astype(np.float32, copy=False) if isinstance(a, np.ndarray) else np.array(a, dtype=np.float32)
            db = b.astype(np.float32, copy=False) if isinstance(b, np.ndarray) else np.array(b, dtype=np.float32)
            diff = np.abs(da - db)
            max_abs = float(np.max(diff)) if diff.size else 0.0
            mean_abs = float(np.mean(diff)) if diff.size else 0.0
            per_out.append({"index": i, "shape": list(getattr(a, "shape", [])), "max_abs": max_abs, "mean_abs": mean_abs})
            max_abs_global = max(max_abs_global, max_abs)
            mean_abs_global += mean_abs
        mean_abs_global = mean_abs_global / float(n)

    passed = (max_abs_global <= float(args.eps)) if n > 0 else True

    def _fmt_pm(mean: Any, std: Any) -> str:
        if mean is None or std is None:
            return "n/a"
        try:
            return f"{float(mean):.3f}  {float(std):.3f}"
        except Exception:
            return "n/a"

    print("==== Timing summary (ms) ====")
    print(f"full     : {_fmt_pm(full_mean, full_std)}")
    print(f"part1    : {_fmt_pm(p1_mean, p1_std)}")
    print(f"part2    : {_fmt_pm(p2_mean, p2_std)}")
    print(f"composed : {_fmt_pm(comp_mean, comp_std)}")
    print("(note) part1+part2 (means) = {:.3f} ms".format(p1_mean + p2_mean))
    if full_mean is None:
        print("(note) composed - full       = n/a")
    else:
        print("(note) composed - full       = {:.3f} ms".format(comp_mean - full_mean))
    print("==== Output diff ====")
    print(f"Compared outputs: {n}")
    print(f"max_abs : {max_abs_global}")
    print(f"mean_abs: {mean_abs_global}")
    print(f"PASS({args.eps}): {passed}")

    report = {
        "created": _now_ts(),
        "created_time_unix": time.time(),
        "manifest": manifest,
        "manifest_path": str(manifest_path),
        "args": vars(args),
        "providers_available": avail,
        "providers_requested": providers,
        "sessions": {"full": info_full.__dict__, "part1": info_p1.__dict__, "part2": info_p2.__dict__},
        "timing_ms": {
            "full_mean": full_mean,
            "full_std": full_std,
            "part1_mean": p1_mean,
            "part1_std": p1_std,
            "part2_mean": p2_mean,
            "part2_std": p2_std,
            "composed_mean": comp_mean,
            "composed_std": comp_std,
        },
        "output_diff": {"eps": float(args.eps), "passed": bool(passed), "max_abs": float(max_abs_global), "mean_abs": float(mean_abs_global), "per_output": per_out},
    }

    # Optional plots
    if not args.no_report_plots:
        _try_write_report_plots(out_dir, report)

    # Optional visualization
    viz_mode = (args.viz or "auto").lower()
    if viz_mode != "none":
        # Determine output names for heuristic detection
        out_names = [o.name for o in sess_full.get_outputs()]

        if viz_mode == "yolo" or (viz_mode == "auto" and _is_yolo_multiscale(full_out)):
            yolo_info = _maybe_yolo_viz(
                out_dir,
                img_path=img_path,
                img_hw=img_hw,
                full_out=full_out,
                comp_out=comp_out,
                conf_thr=float(args.yolo_conf),
                iou_thr=float(args.yolo_iou),
                max_det=int(args.yolo_max_det),
            )
            if yolo_info.get("enabled"):
                report.setdefault("visualization", {})
                report["visualization"]["yolo"] = yolo_info

        if viz_mode == "detr" or (viz_mode == "auto" and _is_detr_like(out_names, full_out)):
            labels = _load_labels(getattr(args, "labels", None))
            detr_info = _maybe_detr_viz(
                out_dir,
                img_path=img_path,
                img_hw=img_hw,
                output_names=out_names,
                full_out=full_out,
                comp_out=comp_out,
                conf_thr=float(getattr(args, "detr_conf", 0.25)),
                iou_thr=float(getattr(args, "detr_iou", 0.50)),
                max_det=int(getattr(args, "detr_max_det", 200)),
                labels=labels,
            )
            if detr_info.get("enabled"):
                report.setdefault("visualization", {})
                report["visualization"]["detr"] = detr_info

    out_report = out_dir / "validation_report.json"
    _write_json(out_report, report)
    print(f"Wrote {out_report}")

    # Clean up Hailo resources if used.
    try:
        if hailo_p1 is not None:
            hailo_p1.close()
        if hailo_p2 is not None:
            hailo_p2.close()
    except Exception as e:
        print(f"[warn] Failed to close Hailo session(s): {e}")

    # For quantized backends (Hailo), numerical diffs vs float baselines can exceed eps.
    # We still record the diff metrics, but we do not fail the run.
    if hailo_hw:
        if not passed:
            print(f"[warn] Output diff exceeds eps={args.eps} (likely due to quantization). Not failing the run.")
        return 0

    return 0 if passed else 2


if __name__ == "__main__":
    raise SystemExit(main())
